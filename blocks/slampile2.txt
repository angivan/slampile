


'''gtf'''
print('\n\n\n1. gtf --- read gtf\n')
df = pd.read_csv(gtf_filename, sep='\t', skiprows=5, header=None)
print(df)



'''gtf --- only select type: gene'''
print('\n\n\n2. gtf --- only select type: gene\n')
df = df[df[2]=='gene']
print(df)



'''gtf --- reduce df columns to ['ensg','chr','start','end','strand']'''
print('''\n\n\n3. gtf --- reduce df columns to ['ensg','chr','start','end','strand']\n''')
ensgs = []
for info in df[8]:
    ensg = get_ensg(info)
    ensgs.append(ensg)
df['ensg'] = ensgs
df['chr'] = df[0]
df['start'] = df[3]
df['end'] = df[4]
df['strand'] = df[6]
df = df[['ensg','chr','start','end','strand']]
print(df)



'''gtf --- check gtf chromosomes'''
chrs = []
for ch in df['chr']:
    if ch not in chrs:
        chrs.append(ch)
print('\n   number of gtf chromosomes: ' + str(len(chrs)))
'''gtf --- check ensg redundancy'''
ensgs.sort()
num_ensg_redundance = 0
for i in range(1,len(ensgs)):
    if ensgs[i] == ensgs[i-1]:
        num_ensg_redundance += 1
print('\n   number of ensg redundance: ' + str(num_ensg_redundance))



'''fa, gtf --- mapping fa chrs to gtf chrs'''
print('''\n\n\n4. fa --- read fa\n''')
'''fa --- checking .fa chromosomes'''
file = open(fa_filename,'r')
lines = file.readlines()
chrs_fa = []
chrs_fa_sequence = []
count=0
for line in lines:
    if line[0] == '>':
        if count!=0:
            chrs_fa_sequence.append(sequence)
        ch_fa=line[1:-1]
        chrs_fa.append(ch_fa)
        count+=1
        sequence = ''
    else:
        sequence += line[:-1]
chrs_fa_sequence.append(sequence)
print('   number of fa chromosomes: ' + str(len(chrs_fa)))



print('''\n\n\n5. fa --- mapping fa chrs to fa sequences\n''')
chrs_fa_sequence_dic = {}
for i in range(len(chrs_fa)):
    chf = chrs_fa[i]
    chrs_fa_sequence_dic[chf] = chrs_fa_sequence[i].upper()#



'''fa --- cross checking fa gtf chromosomes'''
print('''\n\n\n6. gtf,fa --- cross checking fa gtf chromosomes\n''')
chf_ch_dic={}
for chf in chrs_fa:
    string = chf + ': '
    if 'v' in chf:
        chf_change = chf.split('_')[1][:-2] + '.' + chf.split('_')[1][-1]
    else:
        chf_change = chf
    for ch in chrs:
        if chf_change == ch:
            string += ch
            string += ', '
            chf_ch_dic[chf] = ch

ch_chf_dic={}
for chf in chf_ch_dic.keys():
    ch = chf_ch_dic[chf]
    ch_chf_dic[ch] = chf
print('\n   getting gtf2fa & fa2gtf chromosomes dictionary')
print('   number of gtf2fa dictionary chromosomes: ' + str(len(ch_chf_dic)))
print('   number of fa2gtf dictionary chromosomes: ' + str(len(chf_ch_dic)))



'''gtf,fa --- link gtf.ensgs to fa.sequence'''
print('''\n\n\n7. gtf,fa --- link gtf.ensgs to fa.sequence\n''')
'''map ensg to gtf location in such format: chr:start-end'''
df2=df.set_index('ensg')
ensg_location_dic={}
for ensg in ensgs:
    location = df2['chr'][ensg] +':'+ str(df2['start'][ensg]) +'-'+ str(df2['end'][ensg])
    ensg_location_dic[ensg]=location



'''adding gene length and Tcontent to df'''
print('''\n\n\n8. adding gene length and Tcontent to df\n''')
length, Tcontent = [], []
num_keyerror = 0
for ensg in df['ensg']:
    try:
        seq = get_sequence_from_ensg(ensg, ensg_location_dic, ch_chf_dic, chrs_fa_sequence_dic)
        length.append(len(seq))
        Tcontent.append(get_Tcontent(seq))
    except KeyError:
        num_keyerror += 1
        length.append('nif')#nif: not_in_fa
        Tcontent.append('nif')
        
df['length'] = length
df['Tcontent'] = Tcontent
print(df.shape)
df = df[df['length']!='nif']# cut off all the nif
print(df)
print('number of key errors: '+str(num_keyerror))



'''output area'''
print('\n\n\nmajor outputs:\n')
print('1. df')
print('''   gtf as dataframe with columns: ['ensg','chr','start','end','strand','length','Tcontent']''')
print('2. ch_chf_dic')
print('   gtf chromosome ---> fa chromosome')
print('3. chrs_fa_sequence_dic')
print('   fa chromosome ---> fa sequence')
print('4. ensg_location_dic')
print('   ensg ---> fa location')
print('\n')



'''filter out non Ts'''
print('''\n\n\n9. generating coverageOnTs & conversionsOnTs\n''')
pileup_df = pd.read_csv(pileup_filename)
print(pileup_df)

print('\nfiltering for all the Ts\n')# take 1-2 hours to finish
current_chromosome = ''
t_index=[]
for i in range(pileup_df.shape[0]):
    chromosome, position = pileup_df['seqnames'][i], pileup_df['pos'][i]
    if chromosome != current_chromosome:
        current_chromosome = chromosome
        chromosome_sequence = chrs_fa_sequence_dic[chromosome]

    if base_checker(position, chromosome_sequence, base='T') == True:
        t_index.append(i)

pileup_df_t = pileup_df.iloc[t_index]
print(pileup_df_t)
pileup_df_t.to_csv(pileup_filename[:-4] + '.t' + pileup_filename[-4:],index=False)

print('\nstart counting\n')
coverageOnTs, conversionsOnTs = [], []
current_chromosome = ''
for ensg in df['ensg']:
    print(ensg)
    try:
        location = ensg_location_dic[ensg]
        chromosome, start, end = parse_location(location)
        chromosome = ch_chf_dic[chromosome]
        if chromosome != current_chromosome:
            current_chromosome = chromosome
            sel_df1 = pileup_df_t[pileup_df_t['seqnames'] == chromosome]
            value_list = list(sel_df1['pos'])
            lower_index = 0
            sel_df1_row_num = sel_df1.shape[0]
            upper_index = sel_df1_row_num - 1

        '''setting new lower and upper index for current ensg'''
        target_value_start = start
        target_index_start = bisect_search(value_list, target_value_start, lower_index, upper_index, mode = 'find_start')
        target_value_end = end
        try:
            target_index_end = bisect_search(value_list, target_value_end, target_index_start, upper_index, mode = 'find_end')
        except RecursionError:
            print(sel_df1.iloc[target_index_start-5])
            print(sel_df1.iloc[target_index_start-3])
            print(sel_df1.iloc[target_index_start-2])
            print(sel_df1.iloc[target_index_start-1])
            print(sel_df1.iloc[target_index_start])
            print(sel_df1.iloc[target_index_start+1])
            print(sel_df1.iloc[target_index_start+2])
            print(sel_df1.iloc[target_index_start+3])
            print(sel_df1.iloc[target_index_start+4])
            break

        sel_df2 = sel_df1.iloc[target_index_start : target_index_end+1]# select rows

        coverage = get_pileup_count(sel_df2, conversion=False)
        conversion = get_pileup_count(sel_df2, conversion=True)

        coverageOnTs.append(coverage)
        conversionsOnTs.append(conversion)

    except KeyError:
        coverage = 'nif'#nif: not_in_fa
        conversion = 'nif'
        coverageOnTs.append(coverage)
        conversionsOnTs.append(conversion)

    print(coverage)
    print(conversion)

df['coverageOnTs'] = coverageOnTs
df['conversionsOnTs'] = conversionsOnTs
conversionRate = []
for i in range(len(coverageOnTs)):
    coverage = coverageOnTs[i]
    if coverage == 0:
        conversionRate.append('nil')
    else:
        conversion = conversionsOnTs[i]
        cr = conversion/coverage
        conversionRate.append(cr)
df['conversionRate'] = conversionRate
print(df)

df.to_csv(pileup_filename[:-4] + '.conversionStatistic' + pileup_filename[-4:],index=False)
print('SLAM-PILE completed.')
print(pileup_filename[:-4] + '.conversionStatistic' + pileup_filename[-4:])
